{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zeno_client import ZenoClient, ZenoMetric\n",
    "import pandas as pd\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"../../gemini-benchmark/outputs/bbh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = os.listdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models.remove(\".ipynb_checkpoints\")\n",
    "# models.remove(\"mixtral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt-4-1106-preview', 'mixtral', 'gpt-3.5-turbo', 'gemini-pro']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload base dataset\n",
    "df = pd.read_json(os.path.join(OUTPUT_DIR, models[0], \"output.jsonl\"), lines=True)\n",
    "df['task_qid'] = df['task'] +'_'+ df['qid'].astype(str)\n",
    "base_df = pd.DataFrame({\n",
    "    \"qid\": df[\"task_qid\"],\n",
    "    \"question\": df[\"question\"],\n",
    "    \"answer\": df['answer'] \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tir/projects/tir4/users/sakter/anaconda3/envs/bleed/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package zeno-client is out of date. Your version is 0.1.13, the latest is 0.1.14.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "zeno_client = ZenoClient(\"zen_P4CK880bWHV2dJLbAenb0r8Gf6QNLdTXhSkkHqPDm4I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully updated project.\n",
      "Access your project at  https://hub.zenoml.com/project/2302942e-c071-49a1-ba6d-fb9e2ee52cfe/Gemini%20Evaluation%20-%20BBH\n"
     ]
    }
   ],
   "source": [
    "project = zeno_client.create_project(\n",
    "    name=\"Gemini Evaluation - BBH\",\n",
    "    description=\"Evaluation of Gemini, GPT-4, and Mixtral on BBH dataset\",\n",
    "    view={\n",
    "        \"data\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"label\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"output\": {\n",
    "            \"type\": \"text\"\n",
    "        }\n",
    "    },\n",
    "    public=True,\n",
    "    metrics=[\n",
    "        ZenoMetric(name=\"Accuracy Strict Match\", type=\"mean\", columns=[\"is_correct\"]),\n",
    "        ZenoMetric(name=\"Accuracy\", type=\"mean\", columns=[\"is_correct_last\"])\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00903e38698d4a14a0742f68d166bc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded data\n"
     ]
    }
   ],
   "source": [
    "project.upload_dataset(base_df, id_column=\"qid\", data_column=\"question\", label_column=\"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee3545e885e49d6ae26a33c7847b3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b965aad1bfa4124adcc44313d071286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8368e75e10486985a6d716768d73c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603f6d89683343b69a574c3aea029900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def answer_type(answer):\n",
    "    pattern = '[-+]?(?:[0-9,]*\\.*\\d+)'\n",
    "    soln = re.findall(pattern, answer) \n",
    "    if answer.startswith('(') and answer.endswith(')'):\n",
    "        return 'MCQ'\n",
    "    elif answer == 'yes' or answer == 'Yes' or answer == 'No' or answer == 'no':\n",
    "        return 'Yes/No'\n",
    "    elif answer == 'true' or answer == 'True' or answer == 'False' or answer == 'false':\n",
    "        return 'True/False'\n",
    "    elif answer == 'valid' or answer == 'Valid' or answer == 'invalid' or answer == 'Invalid':\n",
    "        return 'Valid/Invalid'\n",
    "    elif len(soln) > 0:\n",
    "        return 'Digit'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "for model in models:\n",
    "    df = pd.read_json(os.path.join(OUTPUT_DIR, model, \"output.jsonl\"), lines=True)\n",
    "    df['task_qid'] = df['task'] +'_'+ df['qid'].astype(str)\n",
    "    output_df = pd.DataFrame({\n",
    "        \"qid\": df[\"task_qid\"],\n",
    "        \"task\": df[\"task\"],\n",
    "        \"output\": df.apply(lambda x: f\"{x['generated_text']}\\n\\n{x['predict']}\", axis=1),\n",
    "        \"output_last\": df.apply(lambda x: f\"{x['predict_last']}\", axis=1),\n",
    "        \"output_type\": df.apply(lambda x: f\"{answer_type(x['answer'])}\", axis=1),\n",
    "        \"question_length\": df.apply(lambda x: len(x['question'].split(' ')), axis=1),\n",
    "        \"output_length\": df.apply(lambda x: len(x['generated_text'].split(' ')), axis=1),\n",
    "        \"is_correct\": df[\"is_correct\"].astype(bool),\n",
    "        \"is_correct_last\": df[\"is_correct_last\"].astype(bool)\n",
    "    })\n",
    "    if model == 'gpt-4-1106-preview':\n",
    "        model = 'gpt-4-turbo'\n",
    "    project.upload_system(output_df, name=model, id_column=\"qid\", output_column=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 task  qid   \n",
      "187   logical_deduction_seven_objects    0  \\\n",
      "188   logical_deduction_seven_objects    1   \n",
      "189   logical_deduction_seven_objects    2   \n",
      "190   logical_deduction_seven_objects    3   \n",
      "191   logical_deduction_seven_objects    4   \n",
      "...                               ...  ...   \n",
      "6506                 geometric_shapes  245   \n",
      "6507                 geometric_shapes  246   \n",
      "6508                 geometric_shapes  247   \n",
      "6509                 geometric_shapes  248   \n",
      "6510                 geometric_shapes  249   \n",
      "\n",
      "                                                 prompt   \n",
      "187    The following paragraphs each describe a set ...  \\\n",
      "188    The following paragraphs each describe a set ...   \n",
      "189    The following paragraphs each describe a set ...   \n",
      "190    The following paragraphs each describe a set ...   \n",
      "191    The following paragraphs each describe a set ...   \n",
      "...                                                 ...   \n",
      "6506   This SVG path element <path d=\"M 31.00,73.00 ...   \n",
      "6507   This SVG path element <path d=\"M 31.00,73.00 ...   \n",
      "6508   This SVG path element <path d=\"M 31.00,73.00 ...   \n",
      "6509   This SVG path element <path d=\"M 31.00,73.00 ...   \n",
      "6510   This SVG path element <path d=\"M 31.00,73.00 ...   \n",
      "\n",
      "                                               question answer   \n",
      "187   The following paragraphs each describe a set o...    (D)  \\\n",
      "188   The following paragraphs each describe a set o...    (B)   \n",
      "189   The following paragraphs each describe a set o...    (A)   \n",
      "190   The following paragraphs each describe a set o...    (A)   \n",
      "191   The following paragraphs each describe a set o...    (F)   \n",
      "...                                                 ...    ...   \n",
      "6506  This SVG path element <path d=\"M 75.62,54.56 L...    (I)   \n",
      "6507  This SVG path element <path d=\"M 33.84,17.25 L...    (I)   \n",
      "6508  This SVG path element <path d=\"M 31.84,9.21 L ...    (K)   \n",
      "6509  This SVG path element <path d=\"M 58.00,35.00 L...    (I)   \n",
      "6510  This SVG path element <path d=\"M 28.86,7.40 L ...    (I)   \n",
      "\n",
      "                                         generated_text   \n",
      "187   (1) Dan finished third: \"(above) ? ? Dan ? ? ?...  \\\n",
      "188   (1) The station wagon is the fourth-newest, wh...   \n",
      "189   (1) The blue jay is the leftmost: \"blue jay ? ...   \n",
      "190   (1) The cardinal is the second from the right:...   \n",
      "191   (1) The pears are the third-cheapest: \"(cheape...   \n",
      "...                                                 ...   \n",
      "6506  This SVG path element contains \"M\", \"L\", and \"...   \n",
      "6507  This SVG path element contains \"M\", \"L\", and \"...   \n",
      "6508  This SVG path element contains \"M\" and \"L\" com...   \n",
      "6509  This SVG path element contains \"M\", \"L\", and \"...   \n",
      "6510  This SVG path element contains \"M\", \"L\", and \"...   \n",
      "\n",
      "                     predict  is_correct  is_correct_last predict_last   \n",
      "187   (D) Dan finished third           0                1          (D)  \\\n",
      "188                      (B)           1                1          (B)   \n",
      "189                      (F)           0                0          (F)   \n",
      "190                      (D)           0                0          (D)   \n",
      "191                      (F)           1                1          (F)   \n",
      "...                      ...         ...              ...          ...   \n",
      "6506                     (I)           1                1          (I)   \n",
      "6507              (I) sector           0                1          (I)   \n",
      "6508                     (J)           0                0          (J)   \n",
      "6509              (I) sector           0                1          (I)   \n",
      "6510                     (I)           1                1          (I)   \n",
      "\n",
      "     output_type  \n",
      "187          MCQ  \n",
      "188          MCQ  \n",
      "189          MCQ  \n",
      "190          MCQ  \n",
      "191          MCQ  \n",
      "...          ...  \n",
      "6506         MCQ  \n",
      "6507         MCQ  \n",
      "6508         MCQ  \n",
      "6509         MCQ  \n",
      "6510         MCQ  \n",
      "\n",
      "[4071 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for model in models:\n",
    "    df = pd.read_json(os.path.join(OUTPUT_DIR, model, \"output.jsonl\"), lines=True)\n",
    "    df[\"output_type\"] = df.apply(lambda x: f\"{answer_type(x['answer'])}\", axis=1)\n",
    "    sub_df = df.loc[df['output_type'] == 'MCQ']\n",
    "    df.groupby('a').count()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join(OUTPUT_DIR, 'gemini-pro', \"output.jsonl\"), lines=True)\n",
    "df[\"output_type\"] = df.apply(lambda x: f\"{answer_type(x['answer'])}\", axis=1)\n",
    "sub_df = df.loc[df['output_type'] == 'MCQ']\n",
    "# sub_df.groupby('predict_last').count()\n",
    "gemini = {}\n",
    "options = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "for op, x in zip(options, sub_df.groupby('predict_last').count()['task'][:6]):\n",
    "    gemini[op] = x/(1.0*len(sub_df))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join(OUTPUT_DIR, 'gpt-3.5-turbo', \"output.jsonl\"), lines=True)\n",
    "df[\"output_type\"] = df.apply(lambda x: f\"{answer_type(x['answer'])}\", axis=1)\n",
    "sub_df = df.loc[df['output_type'] == 'MCQ']\n",
    "# sub_df.groupby('predict_last').count()['task'][:6]\n",
    "gpt_3 = {}\n",
    "options = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "for op, x in zip(options, sub_df.groupby('predict_last').count()['task'][:6]):\n",
    "    gpt_3[op] = x/(1.0*len(sub_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join(OUTPUT_DIR, 'gpt-4-1106-preview', \"output.jsonl\"), lines=True)\n",
    "df[\"output_type\"] = df.apply(lambda x: f\"{answer_type(x['answer'])}\", axis=1)\n",
    "sub_df = df.loc[df['output_type'] == 'MCQ']\n",
    "gpt_4 = {}\n",
    "options = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "for op, x in zip(options, sub_df.groupby('predict_last').count()['task'][:6]):\n",
    "    gpt_4[op] = x/(1.0*len(sub_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join(OUTPUT_DIR, 'mixtral', \"output.jsonl\"), lines=True)\n",
    "df[\"output_type\"] = df.apply(lambda x: f\"{answer_type(x['answer'])}\", axis=1)\n",
    "sub_df = df.loc[df['output_type'] == 'MCQ']\n",
    "# sub_df.groupby('predict_last').count()\n",
    "mixtral = {}\n",
    "options = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "for op, x in zip(options, sub_df.groupby('predict_last').count()['task'][:6]):\n",
    "    mixtral[op] = x/(1.0*len(sub_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04396954065340211"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "179/4071"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemini = {\n",
    "'A': 879,\n",
    "'B': 962,\n",
    "'C': 696,\n",
    "'D': 582,\n",
    "'E': 318,\n",
    "'F': 135}\n",
    "\n",
    "gpt_3 = {\n",
    "    'A': 1056,\n",
    "'B': 942,\n",
    "'C': 743,\n",
    "'D': 590,\n",
    "'E': 312,\n",
    "'F': 132}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'A': 0.2159174649963154,\n",
       "  'B': 0.23630557602554655,\n",
       "  'C': 0.1709653647752395,\n",
       "  'D': 0.14296241709653648,\n",
       "  'E': 0.07811348563006633,\n",
       "  'F': 0.03316138540899042},\n",
       " {'A': 0.2593957258658806,\n",
       "  'B': 0.2313927781871776,\n",
       "  'C': 0.18251043969540653,\n",
       "  'D': 0.14492753623188406,\n",
       "  'E': 0.07663964627855564,\n",
       "  'F': 0.032424465733235076},\n",
       " {'A': 0.24588553181036601,\n",
       "  'B': 0.24957013018914273,\n",
       "  'C': 0.16850896585605502,\n",
       "  'D': 0.13289118152788013,\n",
       "  'E': 0.08253500368459837,\n",
       "  'F': 0.03930238270695161},\n",
       " {'A': 0.20265291083271925,\n",
       "  'B': 0.2164087447801523,\n",
       "  'C': 0.1527880127732744,\n",
       "  'D': 0.1296978629329403,\n",
       "  'E': 0.050110537951363304,\n",
       "  'F': 0.030459346597887498})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini, gpt_3 , gpt_4, mixtral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join(OUTPUT_DIR, 'mixtral', \"output.jsonl\"), lines=True)\n",
    "df[\"output_type\"] = df.apply(lambda x: f\"{answer_type(x['answer'])}\", axis=1)\n",
    "sub_df = df.loc[df['output_type'] == 'MCQ']\n",
    "# sub_df.groupby('predict_last').count()\n",
    "ANSWERS = {}\n",
    "options = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N']\n",
    "for op, x in zip(options, sub_df.groupby('answer').count()['task'][:14]):\n",
    "    ANSWERS[op] = x/(1.0*len(sub_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0.2380250552689757,\n",
       " 'B': 0.25300908867600097,\n",
       " 'C': 0.18275607958732498,\n",
       " 'D': 0.13780397936624908,\n",
       " 'E': 0.07246376811594203,\n",
       " 'F': 0.04618029968066814,\n",
       " 'G': 0.025055268975681652,\n",
       " 'H': 0.0012281994595922379,\n",
       " 'I': 0.009334315892901008,\n",
       " 'J': 0.007369196757553427,\n",
       " 'K': 0.013755833947433063,\n",
       " 'L': 0.0017194792434291329,\n",
       " 'M': 0.0031933185949398184,\n",
       " 'N': 0.0009825595676737902}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANSWERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bleed",
   "language": "python",
   "name": "bleed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
