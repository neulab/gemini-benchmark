{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zeno_client import ZenoClient, ZenoMetric\n",
    "import pandas as pd\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"../../gemini-benchmark/outputs/svamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = os.listdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt-3.5-turbo', 'gpt-4-1106-preview', 'gemini-pro', 'mixtral']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.ipynb_checkpoints\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "models.remove(\".ipynb_checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload base dataset\n",
    "df = pd.read_json(os.path.join(OUTPUT_DIR, models[0], \"output.jsonl\"), lines=True)\n",
    "base_df = pd.DataFrame({\n",
    "    \"qid\": df[\"qid\"],\n",
    "    \"question\": df[\"question\"],\n",
    "    \"answer\": df[\"answer\"].astype(str) \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tir/projects/tir4/users/sakter/anaconda3/envs/bleed/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package zeno-client is out of date. Your version is 0.1.13, the latest is 0.1.14.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "zeno_client = ZenoClient(\"zen_P4CK880bWHV2dJLbAenb0r8Gf6QNLdTXhSkkHqPDm4I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully updated project.\n",
      "Access your project at  https://hub.zenoml.com/project/caa0edd4-467e-44ed-bb89-aa406c2b6e42/Gemini%20Evaluation%20-%20SVAMP\n"
     ]
    }
   ],
   "source": [
    "project = zeno_client.create_project(\n",
    "    name=\"Gemini Evaluation - SVAMP\",\n",
    "    description=\"Evaluation of Gemini, GPT-4, and Mixtral on GSM8k dataset\",\n",
    "    view={\n",
    "        \"data\": {\n",
    "            \"type\": \"markdown\"\n",
    "        },\n",
    "        \"label\": {\n",
    "            \"type\": \"markdown\"\n",
    "        },\n",
    "        \"output\": {\n",
    "            \"type\": \"markdown\"\n",
    "        }\n",
    "    },\n",
    "    public=True,\n",
    "    metrics=[\n",
    "        ZenoMetric(name=\"Accuracy Strict Match\", type=\"mean\", columns=[\"is_correct\"]),\n",
    "        ZenoMetric(name=\"Accuracy\", type=\"mean\", columns=[\"is_correct_last\"])\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d726cb9e294f08a3851841082a9407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded data\n"
     ]
    }
   ],
   "source": [
    "project.upload_dataset(base_df, id_column=\"qid\", data_column=\"question\", label_column=\"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72a385931c6460893551d6b5d6ca502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6409fe0225a4679b215a59093527680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c35725f781543e48d7ebf2f09dd0494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334b59c7f378456db8607cb591330f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    }
   ],
   "source": [
    "def check_fraction(num):\n",
    "    if num % 1 != 0:\n",
    "        print(num)\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "for model in models:\n",
    "    df = pd.read_json(os.path.join(OUTPUT_DIR, model, \"output.jsonl\"), lines=True)\n",
    "    if model == 'mixtral':\n",
    "        output_df = pd.DataFrame({\n",
    "            \"qid\": df[\"qid\"],\n",
    "            \"output\": df.apply(lambda x: f\"{x['generated_text']}\\n\\n**{x['predict']}**\", axis=1),\n",
    "            \"numeric_answer\": df.apply(lambda x: float(x['answer']), axis=1),\n",
    "            \"fraction\": df.apply(lambda x: check_fraction(float(x['answer'])), axis=1),\n",
    "            \"question_length\": df.apply(lambda x: len(x['question'].split(' ')), axis=1),\n",
    "            \"output_length\": df.apply(lambda x: len(x['generated_text'].split('Q:')[0].split(' ')), axis=1),\n",
    "            \"is_correct\": df[\"is_correct\"].astype(bool),\n",
    "            \"is_correct_last\": df[\"is_correct_last\"].astype(bool)\n",
    "        })\n",
    "    else:\n",
    "        output_df = pd.DataFrame({\n",
    "            \"qid\": df[\"qid\"],\n",
    "            \"output\": df.apply(lambda x: f\"{x['generated_text']}\\n\\n**{x['predict']}**\", axis=1),\n",
    "            \"numeric_answer\": df.apply(lambda x: float(x['answer']), axis=1),\n",
    "            \"fraction\": df.apply(lambda x: check_fraction(float(x['answer'])), axis=1),\n",
    "            \"question_length\": df.apply(lambda x: len(x['question'].split(' ')), axis=1),\n",
    "            \"output_length\": df.apply(lambda x: len(x['generated_text'].split(' ')), axis=1),\n",
    "            \"is_correct\": df[\"is_correct\"].astype(bool),\n",
    "            \"is_correct_last\": df[\"is_correct_last\"].astype(bool)\n",
    "        })\n",
    "    if model == 'gpt-4-1106-preview':\n",
    "        model = 'gpt-4-turbo'\n",
    "    project.upload_system(output_df, name=model, id_column=\"qid\", output_column=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bleed",
   "language": "python",
   "name": "bleed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
