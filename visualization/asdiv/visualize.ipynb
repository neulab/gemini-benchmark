{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zeno_client import ZenoClient, ZenoMetric\n",
    "import pandas as pd\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"../../gemini-benchmark/outputs/asdiv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = os.listdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mixtral', 'gemini-pro', 'gpt-4-1106-preview', 'gpt-3.5-turbo']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload base dataset\n",
    "df = pd.read_json(os.path.join(OUTPUT_DIR, models[0], \"output.jsonl\"), lines=True)\n",
    "base_df = pd.DataFrame({\n",
    "    \"qid\": df[\"qid\"],\n",
    "    \"question\": df[\"question\"],\n",
    "    \"answer\": df[\"answer\"].astype(str) \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tir/projects/tir4/users/sakter/anaconda3/envs/bleed/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package zeno-client is out of date. Your version is 0.1.13, the latest is 0.1.14.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "zeno_client = ZenoClient(\"zen_P4CK880bWHV2dJLbAenb0r8Gf6QNLdTXhSkkHqPDm4I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully updated project.\n",
      "Access your project at  https://hub.zenoml.com/project/a8413fa3-f7d7-4616-94fd-fa42ba81d72a/Gemini%20Evaluation%20-%20ASDIV\n"
     ]
    }
   ],
   "source": [
    "project = zeno_client.create_project(\n",
    "    name=\"Gemini Evaluation - ASDIV\",\n",
    "    description=\"Evaluation of Gemini, GPT-4, and Mixtral on ASDIV dataset\",\n",
    "    view={\n",
    "        \"data\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"label\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"output\": {\n",
    "            \"type\": \"markdown\"\n",
    "        }\n",
    "    },\n",
    "    public=True,\n",
    "    metrics=[\n",
    "        ZenoMetric(name=\"Accuracy Strict Match\", type=\"mean\", columns=[\"is_correct\"]),\n",
    "        ZenoMetric(name=\"Accuracy\", type=\"mean\", columns=[\"is_correct_last\"])\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309a6e0e37f743719d19c959aceb3843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded data\n"
     ]
    }
   ],
   "source": [
    "project.upload_dataset(base_df, id_column=\"qid\", data_column=\"question\", label_column=\"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c92d952d9e14425a37cdb6cc80e17e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b5c9cd671b4ffea36db0d6a53ec675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86de7dbe0306442aa4be87872ed94d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244699fb22454575ba6daa6ff1febf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    }
   ],
   "source": [
    "def check_fraction(num):\n",
    "    if num % 1 != 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "for model in models:\n",
    "    df = pd.read_json(os.path.join(OUTPUT_DIR, model, \"output.jsonl\"), lines=True)\n",
    "    if model == 'mixtral':\n",
    "        output_df = pd.DataFrame({\n",
    "            \"qid\": df[\"qid\"],\n",
    "            \"output\": df.apply(lambda x: f\"{x['generated_text']}\\n\\n**{x['predict']}**\", axis=1),\n",
    "            \"answer_str\": df.apply(lambda x: str(x['answer']), axis=1),\n",
    "            \"fraction\": df.apply(lambda x: check_fraction(float(x['answer'])), axis=1),\n",
    "            \"numeric_answer\": df.apply(lambda x: float(x['answer']), axis=1),\n",
    "            \"question_length\": df.apply(lambda x: len(x['question'].split(' ')), axis=1),\n",
    "            \"output_length\": df.apply(lambda x: len(x['generated_text'].split('Q:')[0].split(' ')), axis=1),\n",
    "            \"is_correct\": df[\"is_correct\"].astype(bool),\n",
    "            \"is_correct_last\": df[\"is_correct_last\"].astype(bool)\n",
    "        })\n",
    "    else:\n",
    "        output_df = pd.DataFrame({\n",
    "            \"qid\": df[\"qid\"],\n",
    "            \"output\": df.apply(lambda x: f\"{x['generated_text']}\\n\\n**{x['predict']}**\", axis=1),\n",
    "            \"answer_str\": df.apply(lambda x: str(x['answer']), axis=1),\n",
    "            \"fraction\": df.apply(lambda x: check_fraction(float(x['answer'])), axis=1),\n",
    "            \"numeric_answer\": df.apply(lambda x: float(x['answer']), axis=1),\n",
    "            \"question_length\": df.apply(lambda x: len(x['question'].split(' ')), axis=1),\n",
    "            \"output_length\": df.apply(lambda x: len(x['generated_text'].split(' ')), axis=1),\n",
    "            \"is_correct\": df[\"is_correct\"].astype(bool),\n",
    "            \"is_correct_last\": df[\"is_correct_last\"].astype(bool)\n",
    "        })\n",
    "    if model == 'gpt-4-1106-preview':\n",
    "        model = 'gpt-4-turbo'\n",
    "    project.upload_system(output_df, name=model, id_column=\"qid\", output_column=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bleed",
   "language": "python",
   "name": "bleed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
